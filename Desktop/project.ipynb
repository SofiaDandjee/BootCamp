{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parasitized', 'Uninfected']\n"
     ]
    }
   ],
   "source": [
    "#Training a classifier\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import os\n",
    "\n",
    "print(os.listdir(\"data/cell_images/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import random\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((100,100)), \n",
    "     #transforms.ColorJitter(hue=0.05, saturation=0.05), \n",
    "     transforms.RandomRotation(30),\n",
    "     transforms.RandomVerticalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#import data\n",
    "dataset = datasets.ImageFolder(root = 'data/cell_images', transform=transform)\n",
    "\n",
    "#loader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "#image_means = torch.stack([t.mean(1).mean(1) for t, c in dataset])\n",
    "#image_means.mean(0)\n",
    "\n",
    "n = len(dataset)\n",
    "n_val = int(n*0.1)  #nb of val elms\n",
    "n_test = int(n*0.1) #nb of test elms\n",
    "n_train = n-n_val-n_test\n",
    "\n",
    "train_set, val_set, test_set = data.random_split(dataset, (n_train, n_val, n_test))\n",
    "\n",
    "#define loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=100, shuffle=False, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('Parasitized', 'Uninfected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parasitized Uninfected Parasitized Uninfected Parasitized Uninfected Parasitized Uninfected Uninfected Uninfected Uninfected Uninfected Parasitized Uninfected Uninfected Uninfected Parasitized Parasitized Parasitized Uninfected\n"
     ]
    }
   ],
   "source": [
    "# Show some images, for testing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "    \n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5 #un-normalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "#get rd images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#show imgs\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6400, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Define a CNN\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #self.layer1 = nn.Sequential(\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride = 1)\n",
    "        #nn.ReLU(),\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        #)\n",
    "        #self.layer2 = nn.Sequential(\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size = 3, stride = 1)\n",
    "        #nn.ReLU(),\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        #)\n",
    "        #self.layer3 = nn.Sequential(\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3, stride = 1)\n",
    "        #nn.ReLU(),\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        #)\n",
    "        self.fc1 = nn.Linear(10*10*64, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        #out = self.pool1(F.relu(self.conv1(x)))\n",
    "        #out = self.pool2(F.relu(self.conv2(out)))\n",
    "        #out = self.pool3(F.relu(self.conv3(out)))\n",
    "        out = F.relu(self.conv1(x))\n",
    "        #print(out.shape)\n",
    "        out = self.pool1(out)\n",
    "        #print(out.shape)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        #print(out.shape)\n",
    "        out = self.pool2(out)\n",
    "        #print(out.shape)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        #print(out.shape)\n",
    "        out = self.pool3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc1(out)\n",
    "        #print(out.shape)\n",
    "        out = F.relu(out)\n",
    "        #print(out.shape)\n",
    "        out = self.dropout(out)\n",
    "        #print(out.shape)\n",
    "        out = self.fc2(out)\n",
    "        #print(out.shape)\n",
    "        #out = self.layer1(x)\n",
    "        #out = self.layer2(out)\n",
    "        #out = self.layer3(out)\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        #out = self.layer4(out)\n",
    "        return out\n",
    "\n",
    "#cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = ConvNet()\n",
    "net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, weight_decay = 1e-4, momentum=0.9)\n",
    "#lambda1 = lambda epoch: epoch // 30\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode= 'min',factor=0.1,patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.693\n",
      "[1,   200] loss: 0.693\n",
      "[2,   100] loss: 0.692\n",
      "[2,   200] loss: 0.693\n",
      "[3,   100] loss: 0.693\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "#loss_list = []\n",
    "#acc_list = []\n",
    "net = ConvNet()\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        #zero parameter grads\n",
    "        optimizer.zero_grad()\n",
    "        #scheduler.zero_grad()\n",
    "        \n",
    "        #Run fwd pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #av_loss += loss.item()*0.9+av_loss*0.1\n",
    "        \n",
    "        #Run bwd pass\n",
    "        loss.backward()\n",
    "        #scheduler.step()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i+1, running_loss/100))\n",
    "            running_loss = 0\n",
    "\n",
    "    scheduler.step(running_loss)      \n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
